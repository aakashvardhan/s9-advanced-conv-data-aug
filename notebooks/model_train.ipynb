{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNK90xUH7t9N5TWV1BO+X9g"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"INDe2O0zlHI9","executionInfo":{"status":"ok","timestamp":1711973286173,"user_tz":-240,"elapsed":813,"user":{"displayName":"Aakash Vardhan","userId":"03146811293329168388"}},"outputId":"85e3368b-a3c3-44f8-ccee-155a06580fd3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 's9-advanced-conv-data-aug'...\n","remote: Enumerating objects: 245, done.\u001b[K\n","remote: Counting objects: 100% (245/245), done.\u001b[K\n","remote: Compressing objects: 100% (174/174), done.\u001b[K\n","remote: Total 245 (delta 168), reused 141 (delta 64), pack-reused 0\u001b[K\n","Receiving objects: 100% (245/245), 409.81 KiB | 17.08 MiB/s, done.\n","Resolving deltas: 100% (168/168), done.\n"]}],"source":["!git clone 'https://github.com/aakashvardhan/s9-advanced-conv-data-aug.git'"]},{"cell_type":"code","source":["import sys\n","sys.path.append('/content/s9-advanced-conv-data-aug')\n","sys.path.append('/content/s9-advanced-conv-data-aug/models')"],"metadata":{"id":"6x4yVgd8lUrN","executionInfo":{"status":"ok","timestamp":1711973286174,"user_tz":-240,"elapsed":17,"user":{"displayName":"Aakash Vardhan","userId":"03146811293329168388"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["from config import get_config\n","config = get_config()\n","from main import main\n","import torch\n","torch.manual_seed(1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"34r3l8OSlZHL","executionInfo":{"status":"ok","timestamp":1711973298752,"user_tz":-240,"elapsed":12595,"user":{"displayName":"Aakash Vardhan","userId":"03146811293329168388"}},"outputId":"e85a17c3-38c7-4b52-8687-f109943d873e"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x7d91f411dd50>"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["config['epochs'] = 100\n","config['n_channels'] = 36\n","config['batch_size'] = 128\n","# config['lr_scheduler'] = 'plateau'\n","# config['step_size'] = 10\n","config['lr'] = 0.01\n","config['dropout'] = 0.05"],"metadata":{"id":"RYGO-Y1rmKag","executionInfo":{"status":"ok","timestamp":1711973298753,"user_tz":-240,"elapsed":8,"user":{"displayName":"Aakash Vardhan","userId":"03146811293329168388"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["model, test_loader, lr = main(config)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lzmsolFZlfD6","outputId":"10cc5048-8b30-429c-e2fe-76ce6db39e5e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["CUDA Available? True\n","Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 170498071/170498071 [00:18<00:00, 9442227.97it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/cifar-10-python.tar.gz to ./data\n","Files already downloaded and verified\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n","  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"]},{"output_type":"stream","name":"stdout","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1           [-1, 18, 32, 32]           2,646\n","            Conv2d-2           [-1, 18, 32, 32]           2,646\n","       BatchNorm2d-3           [-1, 18, 32, 32]              36\n","              ReLU-4           [-1, 18, 32, 32]               0\n","           Dropout-5           [-1, 18, 32, 32]               0\n","         ConvBlock-6           [-1, 18, 32, 32]               0\n","            Conv2d-7           [-1, 18, 32, 32]           2,916\n","            Conv2d-8           [-1, 18, 32, 32]           2,916\n","       BatchNorm2d-9           [-1, 18, 32, 32]              36\n","             ReLU-10           [-1, 18, 32, 32]               0\n","          Dropout-11           [-1, 18, 32, 32]               0\n","        ConvBlock-12           [-1, 18, 32, 32]               0\n","           Conv2d-13           [-1, 36, 28, 28]           5,832\n","           Conv2d-14           [-1, 36, 28, 28]           5,832\n","      BatchNorm2d-15           [-1, 36, 28, 28]              72\n","             ReLU-16           [-1, 36, 28, 28]               0\n","          Dropout-17           [-1, 36, 28, 28]               0\n","        ConvBlock-18           [-1, 36, 28, 28]               0\n","           Conv2d-19           [-1, 18, 28, 28]             648\n","  TransitionBlock-20           [-1, 18, 28, 28]               0\n","           Conv2d-21           [-1, 36, 28, 28]           5,832\n","           Conv2d-22           [-1, 36, 28, 28]           5,832\n","      BatchNorm2d-23           [-1, 36, 28, 28]              72\n","             ReLU-24           [-1, 36, 28, 28]               0\n","          Dropout-25           [-1, 36, 28, 28]               0\n","        ConvBlock-26           [-1, 36, 28, 28]               0\n","           Conv2d-27           [-1, 36, 28, 28]          11,664\n","           Conv2d-28           [-1, 36, 28, 28]          11,664\n","      BatchNorm2d-29           [-1, 36, 28, 28]              72\n","             ReLU-30           [-1, 36, 28, 28]               0\n","          Dropout-31           [-1, 36, 28, 28]               0\n","        ConvBlock-32           [-1, 36, 28, 28]               0\n","           Conv2d-33           [-1, 36, 20, 20]          11,664\n","           Conv2d-34           [-1, 36, 20, 20]          11,664\n","      BatchNorm2d-35           [-1, 36, 20, 20]              72\n","             ReLU-36           [-1, 36, 20, 20]               0\n","          Dropout-37           [-1, 36, 20, 20]               0\n","        ConvBlock-38           [-1, 36, 20, 20]               0\n","           Conv2d-39           [-1, 18, 20, 20]             648\n","  TransitionBlock-40           [-1, 18, 20, 20]               0\n","           Conv2d-41           [-1, 18, 20, 20]             162\n","           Conv2d-42           [-1, 18, 20, 20]             162\n","           Conv2d-43           [-1, 36, 20, 20]             648\n","           Conv2d-44           [-1, 36, 20, 20]             648\n","DepthwiseSeparableConv2d-45           [-1, 36, 20, 20]               0\n","DepthwiseSeparableConv2d-46           [-1, 36, 20, 20]               0\n","      BatchNorm2d-47           [-1, 36, 20, 20]              72\n","             ReLU-48           [-1, 36, 20, 20]               0\n","          Dropout-49           [-1, 36, 20, 20]               0\n","        ConvBlock-50           [-1, 36, 20, 20]               0\n","           Conv2d-51           [-1, 36, 20, 20]          11,664\n","           Conv2d-52           [-1, 36, 20, 20]          11,664\n","      BatchNorm2d-53           [-1, 36, 20, 20]              72\n","             ReLU-54           [-1, 36, 20, 20]               0\n","          Dropout-55           [-1, 36, 20, 20]               0\n","        ConvBlock-56           [-1, 36, 20, 20]               0\n","           Conv2d-57             [-1, 36, 4, 4]          11,664\n","           Conv2d-58             [-1, 36, 4, 4]          11,664\n","      BatchNorm2d-59             [-1, 36, 4, 4]              72\n","             ReLU-60             [-1, 36, 4, 4]               0\n","          Dropout-61             [-1, 36, 4, 4]               0\n","        ConvBlock-62             [-1, 36, 4, 4]               0\n","           Conv2d-63             [-1, 18, 4, 4]             648\n","  TransitionBlock-64             [-1, 18, 4, 4]               0\n","           Conv2d-65             [-1, 18, 4, 4]             162\n","           Conv2d-66             [-1, 18, 4, 4]             162\n","           Conv2d-67             [-1, 36, 4, 4]             648\n","           Conv2d-68             [-1, 36, 4, 4]             648\n","DepthwiseSeparableConv2d-69             [-1, 36, 4, 4]               0\n","DepthwiseSeparableConv2d-70             [-1, 36, 4, 4]               0\n","      BatchNorm2d-71             [-1, 36, 4, 4]              72\n","             ReLU-72             [-1, 36, 4, 4]               0\n","          Dropout-73             [-1, 36, 4, 4]               0\n","        ConvBlock-74             [-1, 36, 4, 4]               0\n","           Conv2d-75             [-1, 36, 4, 4]          11,664\n","           Conv2d-76             [-1, 36, 4, 4]          11,664\n","      BatchNorm2d-77             [-1, 36, 4, 4]              72\n","             ReLU-78             [-1, 36, 4, 4]               0\n","          Dropout-79             [-1, 36, 4, 4]               0\n","        ConvBlock-80             [-1, 36, 4, 4]               0\n","           Conv2d-81             [-1, 36, 2, 2]          11,664\n","           Conv2d-82             [-1, 36, 2, 2]          11,664\n","      BatchNorm2d-83             [-1, 36, 2, 2]              72\n","             ReLU-84             [-1, 36, 2, 2]               0\n","          Dropout-85             [-1, 36, 2, 2]               0\n","        ConvBlock-86             [-1, 36, 2, 2]               0\n","AdaptiveAvgPool2d-87             [-1, 36, 1, 1]               0\n","================================================================\n","Total params: 180,396\n","Trainable params: 180,396\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.01\n","Forward/backward pass size (MB): 8.30\n","Params size (MB): 0.69\n","Estimated Total Size (MB): 9.00\n","----------------------------------------------------------------\n","EPOCH: 1\n"]},{"output_type":"stream","name":"stderr","text":["Loss=1.6261800527572632 Batch_id=390 Accuracy=33.71: 100%|██████████| 391/391 [00:16<00:00, 23.92it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 1.4752, Accuracy: 4555/10000 (45.55%)\n","\n","Learning rate: 0.01\n","EPOCH: 2\n"]},{"output_type":"stream","name":"stderr","text":["Loss=1.3888508081436157 Batch_id=390 Accuracy=44.76: 100%|██████████| 391/391 [00:15<00:00, 25.69it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 1.3969, Accuracy: 4949/10000 (49.49%)\n","\n","Learning rate: 0.01\n","EPOCH: 3\n"]},{"output_type":"stream","name":"stderr","text":["Loss=1.3546949625015259 Batch_id=390 Accuracy=49.21: 100%|██████████| 391/391 [00:15<00:00, 25.47it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 1.1833, Accuracy: 5686/10000 (56.86%)\n","\n","Learning rate: 0.01\n","EPOCH: 4\n"]},{"output_type":"stream","name":"stderr","text":["Loss=1.0355188846588135 Batch_id=390 Accuracy=53.29: 100%|██████████| 391/391 [00:15<00:00, 25.34it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 1.1027, Accuracy: 6046/10000 (60.46%)\n","\n","Learning rate: 0.01\n","EPOCH: 5\n"]},{"output_type":"stream","name":"stderr","text":["Loss=1.1099488735198975 Batch_id=390 Accuracy=57.27: 100%|██████████| 391/391 [00:15<00:00, 25.40it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 1.0103, Accuracy: 6408/10000 (64.08%)\n","\n","Learning rate: 0.01\n","EPOCH: 6\n"]},{"output_type":"stream","name":"stderr","text":["Loss=1.1119886636734009 Batch_id=390 Accuracy=59.81: 100%|██████████| 391/391 [00:15<00:00, 25.58it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.9237, Accuracy: 6748/10000 (67.48%)\n","\n","Learning rate: 0.01\n","EPOCH: 7\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.9496116638183594 Batch_id=390 Accuracy=62.02: 100%|██████████| 391/391 [00:14<00:00, 26.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.8938, Accuracy: 6848/10000 (68.48%)\n","\n","Learning rate: 0.001\n","EPOCH: 8\n"]},{"output_type":"stream","name":"stderr","text":["Loss=1.1107325553894043 Batch_id=390 Accuracy=65.42: 100%|██████████| 391/391 [00:15<00:00, 24.83it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.7886, Accuracy: 7219/10000 (72.19%)\n","\n","Learning rate: 0.001\n","EPOCH: 9\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.9167666435241699 Batch_id=390 Accuracy=66.16: 100%|██████████| 391/391 [00:15<00:00, 25.74it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.7780, Accuracy: 7235/10000 (72.35%)\n","\n","Learning rate: 0.001\n","EPOCH: 10\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.8165065050125122 Batch_id=390 Accuracy=66.73: 100%|██████████| 391/391 [00:15<00:00, 25.79it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.7741, Accuracy: 7252/10000 (72.52%)\n","\n","Learning rate: 0.001\n","EPOCH: 11\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.9230548143386841 Batch_id=390 Accuracy=67.22: 100%|██████████| 391/391 [00:14<00:00, 26.19it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.7578, Accuracy: 7314/10000 (73.14%)\n","\n","Learning rate: 0.001\n","EPOCH: 12\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.881999135017395 Batch_id=390 Accuracy=67.40: 100%|██████████| 391/391 [00:15<00:00, 25.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.7573, Accuracy: 7319/10000 (73.19%)\n","\n","Learning rate: 0.001\n","EPOCH: 13\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.8441998362541199 Batch_id=390 Accuracy=67.99: 100%|██████████| 391/391 [00:14<00:00, 26.25it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.7641, Accuracy: 7308/10000 (73.08%)\n","\n","Learning rate: 0.001\n","EPOCH: 14\n"]},{"output_type":"stream","name":"stderr","text":["Loss=1.093106746673584 Batch_id=390 Accuracy=67.91: 100%|██████████| 391/391 [00:14<00:00, 26.14it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.7456, Accuracy: 7360/10000 (73.60%)\n","\n","Learning rate: 0.0001\n","EPOCH: 15\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.7486540079116821 Batch_id=390 Accuracy=68.33: 100%|██████████| 391/391 [00:15<00:00, 25.99it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.7383, Accuracy: 7387/10000 (73.87%)\n","\n","Learning rate: 0.0001\n","EPOCH: 16\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.9660100936889648 Batch_id=390 Accuracy=68.38: 100%|██████████| 391/391 [00:15<00:00, 25.21it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.7385, Accuracy: 7368/10000 (73.68%)\n","\n","Learning rate: 0.0001\n","EPOCH: 17\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.7961371541023254 Batch_id=390 Accuracy=68.60: 100%|██████████| 391/391 [00:14<00:00, 26.14it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.7385, Accuracy: 7380/10000 (73.80%)\n","\n","Learning rate: 0.0001\n","EPOCH: 18\n"]},{"output_type":"stream","name":"stderr","text":["Loss=1.011833906173706 Batch_id=390 Accuracy=68.47: 100%|██████████| 391/391 [00:14<00:00, 26.30it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.7375, Accuracy: 7405/10000 (74.05%)\n","\n","Learning rate: 0.0001\n","EPOCH: 19\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.8877981305122375 Batch_id=390 Accuracy=68.25: 100%|██████████| 391/391 [00:14<00:00, 26.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.7376, Accuracy: 7385/10000 (73.85%)\n","\n","Learning rate: 0.0001\n","EPOCH: 20\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.9666146039962769 Batch_id=390 Accuracy=68.25: 100%|██████████| 391/391 [00:14<00:00, 26.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.7382, Accuracy: 7382/10000 (73.82%)\n","\n","Learning rate: 0.0001\n","EPOCH: 21\n"]},{"output_type":"stream","name":"stderr","text":["Loss=1.0727604627609253 Batch_id=390 Accuracy=68.66: 100%|██████████| 391/391 [00:15<00:00, 25.73it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.7391, Accuracy: 7375/10000 (73.75%)\n","\n","Learning rate: 1e-05\n","EPOCH: 22\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.9860245585441589 Batch_id=390 Accuracy=68.57: 100%|██████████| 391/391 [00:15<00:00, 25.69it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.7357, Accuracy: 7391/10000 (73.91%)\n","\n","Learning rate: 1e-05\n","EPOCH: 23\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.9664772748947144 Batch_id=390 Accuracy=68.73: 100%|██████████| 391/391 [00:15<00:00, 25.29it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.7330, Accuracy: 7395/10000 (73.95%)\n","\n","Learning rate: 1e-05\n","EPOCH: 24\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.9423602819442749 Batch_id=390 Accuracy=68.84: 100%|██████████| 391/391 [00:14<00:00, 26.58it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.7343, Accuracy: 7405/10000 (74.05%)\n","\n","Learning rate: 1e-05\n","EPOCH: 25\n"]},{"output_type":"stream","name":"stderr","text":["Loss=1.0437979698181152 Batch_id=390 Accuracy=68.73: 100%|██████████| 391/391 [00:15<00:00, 25.86it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.7327, Accuracy: 7394/10000 (73.94%)\n","\n","Learning rate: 1e-05\n","EPOCH: 26\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.9178105592727661 Batch_id=390 Accuracy=68.55: 100%|██████████| 391/391 [00:15<00:00, 25.78it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.7326, Accuracy: 7402/10000 (74.02%)\n","\n","Learning rate: 1e-05\n","EPOCH: 27\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.7905251979827881 Batch_id=390 Accuracy=68.69: 100%|██████████| 391/391 [00:16<00:00, 24.42it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.7321, Accuracy: 7408/10000 (74.08%)\n","\n","Learning rate: 1e-05\n","EPOCH: 28\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.9506036043167114 Batch_id=390 Accuracy=68.91: 100%|██████████| 391/391 [00:15<00:00, 26.00it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.7347, Accuracy: 7385/10000 (73.85%)\n","\n","Learning rate: 1.0000000000000002e-06\n","EPOCH: 29\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.9369357228279114 Batch_id=279 Accuracy=68.73:  71%|███████   | 278/391 [00:11<00:03, 28.27it/s]"]}]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","from utils import plt_fig\n","plt_fig()"],"metadata":{"id":"zQqsntJtl43O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from visualize import show_misclassified_images, plt_misclassified_images"],"metadata":{"id":"3st3i0ypl8mv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["misclass_imgs, misclass_targets, misclass_preds = show_misclassified_images(model, test_loader, config)\n","plt_misclassified_images(config, misclass_imgs, misclass_targets, misclass_preds)"],"metadata":{"id":"fGVdlrJEl85B"},"execution_count":null,"outputs":[]}]}