{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNK90xUH7t9N5TWV1BO+X9g"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"INDe2O0zlHI9","executionInfo":{"status":"ok","timestamp":1711971427700,"user_tz":-240,"elapsed":1142,"user":{"displayName":"Aakash Vardhan","userId":"03146811293329168388"}},"outputId":"2dac97e9-25ec-4907-dfe2-46c21911b3c7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 's9-advanced-conv-data-aug'...\n","remote: Enumerating objects: 231, done.\u001b[K\n","remote: Counting objects: 100% (231/231), done.\u001b[K\n","remote: Compressing objects: 100% (158/158), done.\u001b[K\n","remote: Total 231 (delta 156), reused 141 (delta 66), pack-reused 0\u001b[K\n","Receiving objects: 100% (231/231), 401.56 KiB | 2.06 MiB/s, done.\n","Resolving deltas: 100% (156/156), done.\n"]}],"source":["!git clone 'https://github.com/aakashvardhan/s9-advanced-conv-data-aug.git'"]},{"cell_type":"code","source":["import sys\n","sys.path.append('/content/s9-advanced-conv-data-aug')\n","sys.path.append('/content/s9-advanced-conv-data-aug/models')"],"metadata":{"id":"6x4yVgd8lUrN","executionInfo":{"status":"ok","timestamp":1711971427701,"user_tz":-240,"elapsed":3,"user":{"displayName":"Aakash Vardhan","userId":"03146811293329168388"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["from config import get_config\n","config = get_config()\n","from main import main\n","import torch\n","torch.manual_seed(1)"],"metadata":{"id":"34r3l8OSlZHL","executionInfo":{"status":"ok","timestamp":1711971438827,"user_tz":-240,"elapsed":11128,"user":{"displayName":"Aakash Vardhan","userId":"03146811293329168388"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["config['epochs'] = 100\n","config['n_channels'] = 36\n","config['batch_size'] = 128\n","# config['lr_scheduler'] = 'plateau'\n","# config['step_size'] = 10\n","config['lr'] = 0.01\n","config['dropout'] = 0.05"],"metadata":{"id":"RYGO-Y1rmKag","executionInfo":{"status":"ok","timestamp":1711971438827,"user_tz":-240,"elapsed":3,"user":{"displayName":"Aakash Vardhan","userId":"03146811293329168388"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["model, test_loader, lr = main(config)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"lzmsolFZlfD6","executionInfo":{"status":"error","timestamp":1711973030977,"user_tz":-240,"elapsed":1592152,"user":{"displayName":"Aakash Vardhan","userId":"03146811293329168388"}},"outputId":"837a360b-2f1b-4484-d820-8408f2cbf2ef"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["CUDA Available? True\n","Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 170498071/170498071 [00:03<00:00, 43642865.92it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/cifar-10-python.tar.gz to ./data\n","Files already downloaded and verified\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n","  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"]},{"output_type":"stream","name":"stdout","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1           [-1, 18, 32, 32]           2,646\n","            Conv2d-2           [-1, 18, 32, 32]           2,646\n","       BatchNorm2d-3           [-1, 18, 32, 32]              36\n","              ReLU-4           [-1, 18, 32, 32]               0\n","           Dropout-5           [-1, 18, 32, 32]               0\n","         ConvBlock-6           [-1, 18, 32, 32]               0\n","            Conv2d-7           [-1, 18, 32, 32]           2,916\n","            Conv2d-8           [-1, 18, 32, 32]           2,916\n","       BatchNorm2d-9           [-1, 18, 32, 32]              36\n","             ReLU-10           [-1, 18, 32, 32]               0\n","          Dropout-11           [-1, 18, 32, 32]               0\n","        ConvBlock-12           [-1, 18, 32, 32]               0\n","           Conv2d-13           [-1, 36, 28, 28]           5,832\n","           Conv2d-14           [-1, 36, 28, 28]           5,832\n","      BatchNorm2d-15           [-1, 36, 28, 28]              72\n","             ReLU-16           [-1, 36, 28, 28]               0\n","          Dropout-17           [-1, 36, 28, 28]               0\n","        ConvBlock-18           [-1, 36, 28, 28]               0\n","           Conv2d-19           [-1, 18, 28, 28]             648\n","  TransitionBlock-20           [-1, 18, 28, 28]               0\n","           Conv2d-21           [-1, 36, 28, 28]           5,832\n","           Conv2d-22           [-1, 36, 28, 28]           5,832\n","      BatchNorm2d-23           [-1, 36, 28, 28]              72\n","             ReLU-24           [-1, 36, 28, 28]               0\n","          Dropout-25           [-1, 36, 28, 28]               0\n","        ConvBlock-26           [-1, 36, 28, 28]               0\n","           Conv2d-27           [-1, 36, 28, 28]          11,664\n","           Conv2d-28           [-1, 36, 28, 28]          11,664\n","      BatchNorm2d-29           [-1, 36, 28, 28]              72\n","             ReLU-30           [-1, 36, 28, 28]               0\n","          Dropout-31           [-1, 36, 28, 28]               0\n","        ConvBlock-32           [-1, 36, 28, 28]               0\n","           Conv2d-33           [-1, 36, 20, 20]          11,664\n","           Conv2d-34           [-1, 36, 20, 20]          11,664\n","      BatchNorm2d-35           [-1, 36, 20, 20]              72\n","             ReLU-36           [-1, 36, 20, 20]               0\n","          Dropout-37           [-1, 36, 20, 20]               0\n","        ConvBlock-38           [-1, 36, 20, 20]               0\n","           Conv2d-39           [-1, 18, 20, 20]             648\n","  TransitionBlock-40           [-1, 18, 20, 20]               0\n","           Conv2d-41           [-1, 18, 20, 20]             162\n","           Conv2d-42           [-1, 18, 20, 20]             162\n","           Conv2d-43           [-1, 36, 20, 20]             648\n","           Conv2d-44           [-1, 36, 20, 20]             648\n","DepthwiseSeparableConv2d-45           [-1, 36, 20, 20]               0\n","DepthwiseSeparableConv2d-46           [-1, 36, 20, 20]               0\n","      BatchNorm2d-47           [-1, 36, 20, 20]              72\n","             ReLU-48           [-1, 36, 20, 20]               0\n","          Dropout-49           [-1, 36, 20, 20]               0\n","        ConvBlock-50           [-1, 36, 20, 20]               0\n","           Conv2d-51           [-1, 36, 20, 20]          11,664\n","           Conv2d-52           [-1, 36, 20, 20]          11,664\n","      BatchNorm2d-53           [-1, 36, 20, 20]              72\n","             ReLU-54           [-1, 36, 20, 20]               0\n","          Dropout-55           [-1, 36, 20, 20]               0\n","        ConvBlock-56           [-1, 36, 20, 20]               0\n","           Conv2d-57             [-1, 36, 4, 4]          11,664\n","           Conv2d-58             [-1, 36, 4, 4]          11,664\n","      BatchNorm2d-59             [-1, 36, 4, 4]              72\n","             ReLU-60             [-1, 36, 4, 4]               0\n","          Dropout-61             [-1, 36, 4, 4]               0\n","        ConvBlock-62             [-1, 36, 4, 4]               0\n","           Conv2d-63             [-1, 18, 4, 4]             648\n","  TransitionBlock-64             [-1, 18, 4, 4]               0\n","           Conv2d-65             [-1, 18, 4, 4]             162\n","           Conv2d-66             [-1, 18, 4, 4]             162\n","           Conv2d-67             [-1, 36, 4, 4]             648\n","           Conv2d-68             [-1, 36, 4, 4]             648\n","DepthwiseSeparableConv2d-69             [-1, 36, 4, 4]               0\n","DepthwiseSeparableConv2d-70             [-1, 36, 4, 4]               0\n","      BatchNorm2d-71             [-1, 36, 4, 4]              72\n","             ReLU-72             [-1, 36, 4, 4]               0\n","          Dropout-73             [-1, 36, 4, 4]               0\n","        ConvBlock-74             [-1, 36, 4, 4]               0\n","           Conv2d-75             [-1, 36, 4, 4]          11,664\n","           Conv2d-76             [-1, 36, 4, 4]          11,664\n","      BatchNorm2d-77             [-1, 36, 4, 4]              72\n","             ReLU-78             [-1, 36, 4, 4]               0\n","          Dropout-79             [-1, 36, 4, 4]               0\n","        ConvBlock-80             [-1, 36, 4, 4]               0\n","           Conv2d-81             [-1, 36, 2, 2]          11,664\n","           Conv2d-82             [-1, 36, 2, 2]          11,664\n","      BatchNorm2d-83             [-1, 36, 2, 2]              72\n","             ReLU-84             [-1, 36, 2, 2]               0\n","          Dropout-85             [-1, 36, 2, 2]               0\n","        ConvBlock-86             [-1, 36, 2, 2]               0\n","AdaptiveAvgPool2d-87             [-1, 36, 1, 1]               0\n","================================================================\n","Total params: 180,396\n","Trainable params: 180,396\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.01\n","Forward/backward pass size (MB): 8.30\n","Params size (MB): 0.69\n","Estimated Total Size (MB): 9.00\n","----------------------------------------------------------------\n","EPOCH: 1\n"]},{"output_type":"stream","name":"stderr","text":["Loss=1.6886276006698608 Batch_id=390 Accuracy=33.55: 100%|██████████| 391/391 [00:16<00:00, 23.96it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 1.5139, Accuracy: 4454/10000 (44.54%)\n","\n","Learning rate: 0.01\n","EPOCH: 2\n"]},{"output_type":"stream","name":"stderr","text":["Loss=1.3908436298370361 Batch_id=390 Accuracy=44.45: 100%|██████████| 391/391 [00:15<00:00, 25.58it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 1.2847, Accuracy: 5248/10000 (52.48%)\n","\n","Learning rate: 0.01\n","EPOCH: 3\n"]},{"output_type":"stream","name":"stderr","text":["Loss=1.289320468902588 Batch_id=390 Accuracy=49.56: 100%|██████████| 391/391 [00:14<00:00, 26.09it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 1.3229, Accuracy: 5220/10000 (52.20%)\n","\n","Learning rate: 0.01\n","EPOCH: 4\n"]},{"output_type":"stream","name":"stderr","text":["Loss=1.0662049055099487 Batch_id=390 Accuracy=54.03: 100%|██████████| 391/391 [00:15<00:00, 25.95it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 1.0849, Accuracy: 6129/10000 (61.29%)\n","\n","Learning rate: 0.01\n","EPOCH: 5\n"]},{"output_type":"stream","name":"stderr","text":["Loss=1.098828673362732 Batch_id=390 Accuracy=57.45: 100%|██████████| 391/391 [00:14<00:00, 26.07it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 1.0006, Accuracy: 6429/10000 (64.29%)\n","\n","Learning rate: 0.01\n","EPOCH: 6\n"]},{"output_type":"stream","name":"stderr","text":["Loss=1.1021615266799927 Batch_id=390 Accuracy=59.88: 100%|██████████| 391/391 [00:15<00:00, 25.15it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.9850, Accuracy: 6535/10000 (65.35%)\n","\n","Learning rate: 0.01\n","EPOCH: 7\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.8301481008529663 Batch_id=390 Accuracy=61.20: 100%|██████████| 391/391 [00:14<00:00, 26.19it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.8997, Accuracy: 6815/10000 (68.15%)\n","\n","Learning rate: 0.01\n","EPOCH: 8\n"]},{"output_type":"stream","name":"stderr","text":["Loss=1.0085426568984985 Batch_id=390 Accuracy=62.75: 100%|██████████| 391/391 [00:15<00:00, 25.85it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.8769, Accuracy: 6881/10000 (68.81%)\n","\n","Learning rate: 0.01\n","EPOCH: 9\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.8950241208076477 Batch_id=390 Accuracy=64.12: 100%|██████████| 391/391 [00:15<00:00, 25.95it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.8436, Accuracy: 7008/10000 (70.08%)\n","\n","Learning rate: 0.01\n","EPOCH: 10\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.8707664608955383 Batch_id=390 Accuracy=65.11: 100%|██████████| 391/391 [00:15<00:00, 24.53it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.8200, Accuracy: 7141/10000 (71.41%)\n","\n","Learning rate: 0.01\n","EPOCH: 11\n"]},{"output_type":"stream","name":"stderr","text":["Loss=1.021891474723816 Batch_id=390 Accuracy=65.99: 100%|██████████| 391/391 [00:15<00:00, 25.86it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.7786, Accuracy: 7257/10000 (72.57%)\n","\n","Learning rate: 0.01\n","EPOCH: 12\n"]},{"output_type":"stream","name":"stderr","text":["Loss=1.1598656177520752 Batch_id=390 Accuracy=66.85: 100%|██████████| 391/391 [00:15<00:00, 25.88it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.8012, Accuracy: 7207/10000 (72.07%)\n","\n","Learning rate: 0.01\n","EPOCH: 13\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.8556066751480103 Batch_id=390 Accuracy=67.23: 100%|██████████| 391/391 [00:15<00:00, 25.82it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.7380, Accuracy: 7416/10000 (74.16%)\n","\n","Learning rate: 0.01\n","EPOCH: 14\n"]},{"output_type":"stream","name":"stderr","text":["Loss=1.042014718055725 Batch_id=390 Accuracy=68.25: 100%|██████████| 391/391 [00:15<00:00, 25.73it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.7530, Accuracy: 7324/10000 (73.24%)\n","\n","Learning rate: 0.01\n","EPOCH: 15\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.6860766410827637 Batch_id=390 Accuracy=68.70: 100%|██████████| 391/391 [00:15<00:00, 25.89it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.7658, Accuracy: 7305/10000 (73.05%)\n","\n","Learning rate: 0.01\n","EPOCH: 16\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.9349476099014282 Batch_id=390 Accuracy=68.90: 100%|██████████| 391/391 [00:15<00:00, 25.89it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.7301, Accuracy: 7432/10000 (74.32%)\n","\n","Learning rate: 0.01\n","EPOCH: 17\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.6734355688095093 Batch_id=390 Accuracy=69.75: 100%|██████████| 391/391 [00:15<00:00, 24.59it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.7097, Accuracy: 7486/10000 (74.86%)\n","\n","Learning rate: 0.01\n","EPOCH: 18\n"]},{"output_type":"stream","name":"stderr","text":["Loss=1.0214710235595703 Batch_id=390 Accuracy=70.12: 100%|██████████| 391/391 [00:14<00:00, 26.13it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.7317, Accuracy: 7429/10000 (74.29%)\n","\n","Learning rate: 0.01\n","EPOCH: 19\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.7407814264297485 Batch_id=390 Accuracy=70.44: 100%|██████████| 391/391 [00:15<00:00, 25.67it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.6856, Accuracy: 7582/10000 (75.82%)\n","\n","Learning rate: 0.01\n","EPOCH: 20\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.8605467081069946 Batch_id=390 Accuracy=70.89: 100%|██████████| 391/391 [00:14<00:00, 26.19it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.7511, Accuracy: 7413/10000 (74.13%)\n","\n","Learning rate: 0.01\n","EPOCH: 21\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.9663993120193481 Batch_id=390 Accuracy=71.46: 100%|██████████| 391/391 [00:15<00:00, 25.14it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.6979, Accuracy: 7574/10000 (75.74%)\n","\n","Learning rate: 0.01\n","EPOCH: 22\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.9155941009521484 Batch_id=390 Accuracy=71.65: 100%|██████████| 391/391 [00:14<00:00, 26.31it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.6617, Accuracy: 7706/10000 (77.06%)\n","\n","Learning rate: 0.01\n","EPOCH: 23\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.7835640907287598 Batch_id=390 Accuracy=72.14: 100%|██████████| 391/391 [00:15<00:00, 25.92it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.6724, Accuracy: 7665/10000 (76.65%)\n","\n","Learning rate: 0.01\n","EPOCH: 24\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.8795334696769714 Batch_id=390 Accuracy=72.23: 100%|██████████| 391/391 [00:15<00:00, 24.90it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.6793, Accuracy: 7616/10000 (76.16%)\n","\n","Learning rate: 0.01\n","EPOCH: 25\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.9249109029769897 Batch_id=390 Accuracy=72.45: 100%|██████████| 391/391 [00:14<00:00, 26.08it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.6510, Accuracy: 7743/10000 (77.43%)\n","\n","Learning rate: 0.01\n","EPOCH: 26\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.7456891536712646 Batch_id=390 Accuracy=72.96: 100%|██████████| 391/391 [00:15<00:00, 26.00it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.6610, Accuracy: 7725/10000 (77.25%)\n","\n","Learning rate: 0.01\n","EPOCH: 27\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.6510003805160522 Batch_id=390 Accuracy=73.38: 100%|██████████| 391/391 [00:14<00:00, 26.25it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.6399, Accuracy: 7775/10000 (77.75%)\n","\n","Learning rate: 0.01\n","EPOCH: 28\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.8255847096443176 Batch_id=390 Accuracy=73.64: 100%|██████████| 391/391 [00:15<00:00, 25.06it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.6455, Accuracy: 7804/10000 (78.04%)\n","\n","Learning rate: 0.01\n","EPOCH: 29\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.6921588182449341 Batch_id=390 Accuracy=73.58: 100%|██████████| 391/391 [00:15<00:00, 25.68it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.6741, Accuracy: 7679/10000 (76.79%)\n","\n","Learning rate: 0.01\n","EPOCH: 30\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.7979965209960938 Batch_id=390 Accuracy=73.78: 100%|██████████| 391/391 [00:15<00:00, 25.57it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.6063, Accuracy: 7879/10000 (78.79%)\n","\n","Learning rate: 0.01\n","EPOCH: 31\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.689652681350708 Batch_id=390 Accuracy=73.86: 100%|██████████| 391/391 [00:15<00:00, 25.42it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.6078, Accuracy: 7911/10000 (79.11%)\n","\n","Learning rate: 0.01\n","EPOCH: 32\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.7649233937263489 Batch_id=390 Accuracy=74.35: 100%|██████████| 391/391 [00:15<00:00, 25.63it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.5903, Accuracy: 7977/10000 (79.77%)\n","\n","Learning rate: 0.01\n","EPOCH: 33\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.700658917427063 Batch_id=390 Accuracy=74.47: 100%|██████████| 391/391 [00:15<00:00, 25.99it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.5843, Accuracy: 7990/10000 (79.90%)\n","\n","Learning rate: 0.01\n","EPOCH: 34\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.5665692090988159 Batch_id=390 Accuracy=74.58: 100%|██████████| 391/391 [00:15<00:00, 25.85it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.6533, Accuracy: 7770/10000 (77.70%)\n","\n","Learning rate: 0.01\n","EPOCH: 35\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.483059823513031 Batch_id=390 Accuracy=74.61: 100%|██████████| 391/391 [00:15<00:00, 24.95it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.6136, Accuracy: 7884/10000 (78.84%)\n","\n","Learning rate: 0.01\n","EPOCH: 36\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.684431254863739 Batch_id=390 Accuracy=74.89: 100%|██████████| 391/391 [00:15<00:00, 25.96it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.6350, Accuracy: 7778/10000 (77.78%)\n","\n","Learning rate: 0.01\n","EPOCH: 37\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.5398880839347839 Batch_id=390 Accuracy=74.86: 100%|██████████| 391/391 [00:15<00:00, 25.88it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.5636, Accuracy: 8050/10000 (80.50%)\n","\n","Learning rate: 0.01\n","EPOCH: 38\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.7068969011306763 Batch_id=390 Accuracy=75.34: 100%|██████████| 391/391 [00:15<00:00, 25.90it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.5887, Accuracy: 7980/10000 (79.80%)\n","\n","Learning rate: 0.01\n","EPOCH: 39\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.7944501042366028 Batch_id=390 Accuracy=75.43: 100%|██████████| 391/391 [00:15<00:00, 25.81it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.5700, Accuracy: 8045/10000 (80.45%)\n","\n","Learning rate: 0.01\n","EPOCH: 40\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.7120112776756287 Batch_id=390 Accuracy=75.48: 100%|██████████| 391/391 [00:15<00:00, 26.05it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.5801, Accuracy: 8032/10000 (80.32%)\n","\n","Learning rate: 0.01\n","EPOCH: 41\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.6641862392425537 Batch_id=390 Accuracy=75.65: 100%|██████████| 391/391 [00:15<00:00, 25.68it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.5646, Accuracy: 8099/10000 (80.99%)\n","\n","Learning rate: 0.01\n","EPOCH: 42\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.7081817984580994 Batch_id=390 Accuracy=75.80: 100%|██████████| 391/391 [00:15<00:00, 24.85it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.5407, Accuracy: 8147/10000 (81.47%)\n","\n","Learning rate: 0.01\n","EPOCH: 43\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.9015432596206665 Batch_id=390 Accuracy=76.19: 100%|██████████| 391/391 [00:15<00:00, 25.73it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.5682, Accuracy: 8016/10000 (80.16%)\n","\n","Learning rate: 0.01\n","EPOCH: 44\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.6307628154754639 Batch_id=390 Accuracy=76.09: 100%|██████████| 391/391 [00:15<00:00, 25.98it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.5872, Accuracy: 8029/10000 (80.29%)\n","\n","Learning rate: 0.01\n","EPOCH: 45\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.879686176776886 Batch_id=390 Accuracy=76.22: 100%|██████████| 391/391 [00:15<00:00, 26.06it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.5874, Accuracy: 7980/10000 (79.80%)\n","\n","Learning rate: 0.01\n","EPOCH: 46\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.677280068397522 Batch_id=390 Accuracy=76.27: 100%|██████████| 391/391 [00:15<00:00, 25.51it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.5992, Accuracy: 7976/10000 (79.76%)\n","\n","Learning rate: 0.01\n","EPOCH: 47\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.7417609691619873 Batch_id=390 Accuracy=76.47: 100%|██████████| 391/391 [00:15<00:00, 25.94it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.5788, Accuracy: 8028/10000 (80.28%)\n","\n","Learning rate: 0.01\n","EPOCH: 48\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.5535861849784851 Batch_id=390 Accuracy=76.52: 100%|██████████| 391/391 [00:15<00:00, 25.41it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.5750, Accuracy: 8028/10000 (80.28%)\n","\n","Learning rate: 0.001\n","EPOCH: 49\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.6306140422821045 Batch_id=390 Accuracy=78.18: 100%|██████████| 391/391 [00:15<00:00, 25.10it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.4984, Accuracy: 8298/10000 (82.98%)\n","\n","Learning rate: 0.001\n","EPOCH: 50\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.5720585584640503 Batch_id=390 Accuracy=78.41: 100%|██████████| 391/391 [00:15<00:00, 25.82it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.4961, Accuracy: 8288/10000 (82.88%)\n","\n","Learning rate: 0.001\n","EPOCH: 51\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.4972231984138489 Batch_id=390 Accuracy=78.76: 100%|██████████| 391/391 [00:14<00:00, 26.10it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.4941, Accuracy: 8291/10000 (82.91%)\n","\n","Learning rate: 0.001\n","EPOCH: 52\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.5444138050079346 Batch_id=390 Accuracy=78.91: 100%|██████████| 391/391 [00:15<00:00, 25.68it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.4941, Accuracy: 8310/10000 (83.10%)\n","\n","Learning rate: 0.001\n","EPOCH: 53\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.5928665399551392 Batch_id=390 Accuracy=78.89: 100%|██████████| 391/391 [00:15<00:00, 24.82it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.4936, Accuracy: 8313/10000 (83.13%)\n","\n","Learning rate: 0.001\n","EPOCH: 54\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.48045986890792847 Batch_id=390 Accuracy=78.93: 100%|██████████| 391/391 [00:15<00:00, 25.49it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.4908, Accuracy: 8314/10000 (83.14%)\n","\n","Learning rate: 0.001\n","EPOCH: 55\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.6532817482948303 Batch_id=390 Accuracy=78.88: 100%|██████████| 391/391 [00:15<00:00, 25.59it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.4914, Accuracy: 8308/10000 (83.08%)\n","\n","Learning rate: 0.001\n","EPOCH: 56\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.5576940774917603 Batch_id=390 Accuracy=78.72: 100%|██████████| 391/391 [00:15<00:00, 24.82it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.4870, Accuracy: 8297/10000 (82.97%)\n","\n","Learning rate: 0.001\n","EPOCH: 57\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.5746740698814392 Batch_id=390 Accuracy=79.13: 100%|██████████| 391/391 [00:15<00:00, 25.83it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.4899, Accuracy: 8309/10000 (83.09%)\n","\n","Learning rate: 0.001\n","EPOCH: 58\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.6796285510063171 Batch_id=390 Accuracy=78.98: 100%|██████████| 391/391 [00:15<00:00, 25.83it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.4935, Accuracy: 8318/10000 (83.18%)\n","\n","Learning rate: 0.001\n","EPOCH: 59\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.648237407207489 Batch_id=390 Accuracy=79.14: 100%|██████████| 391/391 [00:15<00:00, 25.72it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.4891, Accuracy: 8339/10000 (83.39%)\n","\n","Learning rate: 0.001\n","EPOCH: 60\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.8462530970573425 Batch_id=390 Accuracy=79.25: 100%|██████████| 391/391 [00:15<00:00, 24.80it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.4845, Accuracy: 8340/10000 (83.40%)\n","\n","Learning rate: 0.001\n","EPOCH: 61\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.4321761131286621 Batch_id=390 Accuracy=79.28: 100%|██████████| 391/391 [00:15<00:00, 25.67it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.4886, Accuracy: 8324/10000 (83.24%)\n","\n","Learning rate: 0.001\n","EPOCH: 62\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.7526658177375793 Batch_id=390 Accuracy=79.22: 100%|██████████| 391/391 [00:14<00:00, 26.09it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.4847, Accuracy: 8331/10000 (83.31%)\n","\n","Learning rate: 0.001\n","EPOCH: 63\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.7120278477668762 Batch_id=390 Accuracy=79.34: 100%|██████████| 391/391 [00:15<00:00, 25.20it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.4872, Accuracy: 8331/10000 (83.31%)\n","\n","Learning rate: 0.001\n","EPOCH: 64\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.45183730125427246 Batch_id=390 Accuracy=79.21: 100%|██████████| 391/391 [00:15<00:00, 25.85it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.4907, Accuracy: 8327/10000 (83.27%)\n","\n","Learning rate: 0.001\n","EPOCH: 65\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.5018101930618286 Batch_id=390 Accuracy=79.30: 100%|██████████| 391/391 [00:15<00:00, 25.67it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.4906, Accuracy: 8340/10000 (83.40%)\n","\n","Learning rate: 0.001\n","EPOCH: 66\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.6184120774269104 Batch_id=390 Accuracy=79.34: 100%|██████████| 391/391 [00:15<00:00, 25.53it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.4851, Accuracy: 8360/10000 (83.60%)\n","\n","Learning rate: 0.0001\n","EPOCH: 67\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.7078574299812317 Batch_id=390 Accuracy=79.45: 100%|██████████| 391/391 [00:16<00:00, 24.43it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.4836, Accuracy: 8367/10000 (83.67%)\n","\n","Learning rate: 0.0001\n","EPOCH: 68\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.5663670301437378 Batch_id=390 Accuracy=79.52: 100%|██████████| 391/391 [00:15<00:00, 25.43it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.4843, Accuracy: 8359/10000 (83.59%)\n","\n","Learning rate: 0.0001\n","EPOCH: 69\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.5085601806640625 Batch_id=390 Accuracy=79.48: 100%|██████████| 391/391 [00:15<00:00, 25.71it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.4858, Accuracy: 8349/10000 (83.49%)\n","\n","Learning rate: 0.0001\n","EPOCH: 70\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.5395990014076233 Batch_id=390 Accuracy=79.65: 100%|██████████| 391/391 [00:15<00:00, 25.41it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.4806, Accuracy: 8362/10000 (83.62%)\n","\n","Learning rate: 0.0001\n","EPOCH: 71\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.623952329158783 Batch_id=390 Accuracy=79.41: 100%|██████████| 391/391 [00:15<00:00, 25.74it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.4831, Accuracy: 8365/10000 (83.65%)\n","\n","Learning rate: 0.0001\n","EPOCH: 72\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.4783340394496918 Batch_id=390 Accuracy=79.46: 100%|██████████| 391/391 [00:15<00:00, 25.51it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.4811, Accuracy: 8360/10000 (83.60%)\n","\n","Learning rate: 0.0001\n","EPOCH: 73\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.7047790288925171 Batch_id=390 Accuracy=79.36: 100%|██████████| 391/391 [00:15<00:00, 25.76it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.4819, Accuracy: 8352/10000 (83.52%)\n","\n","Learning rate: 0.0001\n","EPOCH: 74\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.4250022768974304 Batch_id=390 Accuracy=79.47: 100%|██████████| 391/391 [00:16<00:00, 24.36it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.4809, Accuracy: 8359/10000 (83.59%)\n","\n","Learning rate: 0.0001\n","EPOCH: 75\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.5633596181869507 Batch_id=390 Accuracy=79.78: 100%|██████████| 391/391 [00:15<00:00, 25.66it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.4811, Accuracy: 8361/10000 (83.61%)\n","\n","Learning rate: 0.0001\n","EPOCH: 76\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.5735910534858704 Batch_id=390 Accuracy=79.74: 100%|██████████| 391/391 [00:15<00:00, 25.44it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.4829, Accuracy: 8351/10000 (83.51%)\n","\n","Learning rate: 1e-05\n","EPOCH: 77\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.3778206706047058 Batch_id=390 Accuracy=79.65: 100%|██████████| 391/391 [00:17<00:00, 22.21it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.4774, Accuracy: 8366/10000 (83.66%)\n","\n","Learning rate: 1e-05\n","EPOCH: 78\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.761258065700531 Batch_id=390 Accuracy=79.48: 100%|██████████| 391/391 [00:16<00:00, 24.21it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.4835, Accuracy: 8347/10000 (83.47%)\n","\n","Learning rate: 1e-05\n","EPOCH: 79\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.6599880456924438 Batch_id=390 Accuracy=79.54: 100%|██████████| 391/391 [00:15<00:00, 25.26it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.4819, Accuracy: 8354/10000 (83.54%)\n","\n","Learning rate: 1e-05\n","EPOCH: 80\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.5214197635650635 Batch_id=390 Accuracy=79.54: 100%|██████████| 391/391 [00:15<00:00, 24.87it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.4831, Accuracy: 8347/10000 (83.47%)\n","\n","Learning rate: 1e-05\n","EPOCH: 81\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.5257135033607483 Batch_id=390 Accuracy=79.68: 100%|██████████| 391/391 [00:15<00:00, 25.55it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.4817, Accuracy: 8363/10000 (83.63%)\n","\n","Learning rate: 1e-05\n","EPOCH: 82\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.6069096922874451 Batch_id=390 Accuracy=79.65: 100%|██████████| 391/391 [00:15<00:00, 25.39it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.4808, Accuracy: 8359/10000 (83.59%)\n","\n","Learning rate: 1e-05\n","EPOCH: 83\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.5707800984382629 Batch_id=390 Accuracy=79.54: 100%|██████████| 391/391 [00:15<00:00, 25.36it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.4809, Accuracy: 8368/10000 (83.68%)\n","\n","Learning rate: 1.0000000000000002e-06\n","EPOCH: 84\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.49542421102523804 Batch_id=390 Accuracy=79.56: 100%|██████████| 391/391 [00:15<00:00, 24.86it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.4816, Accuracy: 8360/10000 (83.60%)\n","\n","Learning rate: 1.0000000000000002e-06\n","EPOCH: 85\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.5693151950836182 Batch_id=390 Accuracy=79.54: 100%|██████████| 391/391 [00:15<00:00, 25.24it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.4795, Accuracy: 8374/10000 (83.74%)\n","\n","Learning rate: 1.0000000000000002e-06\n","EPOCH: 86\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.6322013735771179 Batch_id=390 Accuracy=79.58: 100%|██████████| 391/391 [00:15<00:00, 25.23it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.4798, Accuracy: 8366/10000 (83.66%)\n","\n","Learning rate: 1.0000000000000002e-06\n","EPOCH: 87\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.49030834436416626 Batch_id=390 Accuracy=79.45: 100%|██████████| 391/391 [00:15<00:00, 24.58it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.4809, Accuracy: 8361/10000 (83.61%)\n","\n","Learning rate: 1.0000000000000002e-06\n","EPOCH: 88\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.5747259259223938 Batch_id=390 Accuracy=79.53: 100%|██████████| 391/391 [00:15<00:00, 25.58it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.4820, Accuracy: 8354/10000 (83.54%)\n","\n","Learning rate: 1.0000000000000002e-06\n","EPOCH: 89\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.5808359384536743 Batch_id=390 Accuracy=79.44: 100%|██████████| 391/391 [00:15<00:00, 25.40it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.4800, Accuracy: 8362/10000 (83.62%)\n","\n","Learning rate: 1.0000000000000002e-07\n","EPOCH: 90\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.637889564037323 Batch_id=390 Accuracy=79.61: 100%|██████████| 391/391 [00:15<00:00, 25.44it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.4821, Accuracy: 8352/10000 (83.52%)\n","\n","Learning rate: 1.0000000000000002e-07\n","EPOCH: 91\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.5874156951904297 Batch_id=390 Accuracy=79.56: 100%|██████████| 391/391 [00:15<00:00, 25.17it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.4813, Accuracy: 8357/10000 (83.57%)\n","\n","Learning rate: 1.0000000000000002e-07\n","EPOCH: 92\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.6446945667266846 Batch_id=390 Accuracy=79.57: 100%|██████████| 391/391 [00:15<00:00, 25.34it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.4801, Accuracy: 8373/10000 (83.73%)\n","\n","Learning rate: 1.0000000000000002e-07\n","EPOCH: 93\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.5572731494903564 Batch_id=390 Accuracy=79.61: 100%|██████████| 391/391 [00:15<00:00, 25.21it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.4821, Accuracy: 8362/10000 (83.62%)\n","\n","Learning rate: 1.0000000000000002e-07\n","EPOCH: 94\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.5940678119659424 Batch_id=390 Accuracy=79.48: 100%|██████████| 391/391 [00:16<00:00, 23.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.4830, Accuracy: 8354/10000 (83.54%)\n","\n","Learning rate: 1.0000000000000002e-07\n","EPOCH: 95\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.5410073399543762 Batch_id=114 Accuracy=79.51:  29%|██▉       | 115/391 [00:04<00:11, 24.78it/s]\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-a5db96f8b983>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/content/s9-advanced-conv-data-aug/main.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epochs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"EPOCH:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'device'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mtest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'device'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr_scheduler'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'step_lr'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/s9-advanced-conv-data-aug/utils.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, device, train_loader, optimizer, epoch)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m# Init\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;31m# In PyTorch, we need to set the gradients to zero before starting to do backpropragation because PyTorch accumulates the gradients on subsequent backward passes.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m# Because of this, when you start your training loop, ideally you should zero out the gradients so that you do the parameter update correctly.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_compile.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_dynamo/decorators.py\u001b[0m in \u001b[0;36mdisable\u001b[0;34m(fn, recursive)\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0mfn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minnermost_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mDisableContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mDisableContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 437\u001b[0;31m             \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetsourcefile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    438\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m             \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/inspect.py\u001b[0m in \u001b[0;36mgetsourcefile\u001b[0;34m(object)\u001b[0m\n\u001b[1;32m    824\u001b[0m                  importlib.machinery.EXTENSION_SUFFIXES):\n\u001b[1;32m    825\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 826\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    827\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m     \u001b[0;31m# only return a non-existent filename if the module has a PEP 302 loader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/genericpath.py\u001b[0m in \u001b[0;36mexists\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;34m\"\"\"Test whether a path exists.  Returns False for broken symbolic links\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mOSError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","from utils import plt_fig\n","plt_fig()"],"metadata":{"id":"zQqsntJtl43O","executionInfo":{"status":"aborted","timestamp":1711973030977,"user_tz":-240,"elapsed":4,"user":{"displayName":"Aakash Vardhan","userId":"03146811293329168388"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from visualize import show_misclassified_images, plt_misclassified_images"],"metadata":{"id":"3st3i0ypl8mv","executionInfo":{"status":"aborted","timestamp":1711973030978,"user_tz":-240,"elapsed":5,"user":{"displayName":"Aakash Vardhan","userId":"03146811293329168388"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["misclass_imgs, misclass_targets, misclass_preds = show_misclassified_images(model, test_loader, config)\n","plt_misclassified_images(config, misclass_imgs, misclass_targets, misclass_preds)"],"metadata":{"id":"fGVdlrJEl85B","executionInfo":{"status":"aborted","timestamp":1711973030978,"user_tz":-240,"elapsed":5,"user":{"displayName":"Aakash Vardhan","userId":"03146811293329168388"}}},"execution_count":null,"outputs":[]}]}